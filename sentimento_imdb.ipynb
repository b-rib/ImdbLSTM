{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for classifying feelings (IMDb dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tqdm\n",
    "# import kormos\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, LSTM, Flatten\n",
    "from keras.layers import TextVectorization\n",
    "from aux_we import generate_training_data\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\", \"/gpu:4\"])\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "if not(os.path.exists('aclImdb_v1.tar.gz')):\n",
    "    print(\"===== Downloading Imdb Dataset =====\")\n",
    "    dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "    dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    remove_dir = os.path.join(train_dir, 'unsup')\n",
    "    shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 127\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='training', seed=seed)\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='validation', seed=seed)\n",
    "\n",
    "#Change to true to see a sample\n",
    "print_one = False\n",
    "if print_one:\n",
    "    for text_batch, label_batch in train_ds.take(1):\n",
    "        for i in range(1):\n",
    "            print(f\"Review: {text_batch.numpy()[i]}\")\n",
    "            print(f\"Label: {label_batch.numpy()[i]}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  nots = tf.strings.regex_replace(lowercase, 'n\\'t', ' not')\n",
    "  ss = tf.strings.regex_replace(nots, '\\'s', '')\n",
    "  stripped_html = tf.strings.regex_replace(ss, '<br />', ' ')\n",
    "  no_ponctuation = tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation), '')\n",
    "  single_spaces = tf.strings.regex_replace(no_ponctuation, '  ', ' ')\n",
    "  for i in range(2):\n",
    "    single_spaces = tf.strings.regex_replace(single_spaces, '  ', ' ')\n",
    "  return single_spaces\n",
    "\n",
    "dictionary_size = 2000\n",
    "max_review_size = 250\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=dictionary_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_review_size)\n",
    "\n",
    "#Build dictonary\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "text_ds = text_ds.cache().prefetch(buffer_size=10)\n",
    "vectorize_layer.adapt(text_ds)\n",
    "\n",
    "#Print one\n",
    "# text_batch, label_batch = next(iter(train_ds))\n",
    "# first_review, first_label = text_batch[10], label_batch[10]\n",
    "# print(\"Review\", custom_standardization(first_review))\n",
    "# print(\"Label\", train_ds.class_names[first_label])\n",
    "# print(\"Vectorized review\", vectorize_layer(first_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(b'its no surprise that busey later developed a tumor in his sinus cavity this film is also a poor decision but one i enjoyed fully the first 5 minutes is the most uninspiring 5 minutes in any film boring bad dialouge and then with a spiderman stance busey yells the bestworst line in any film ever createdyour worst nightmare butthorn i coughed up some of my egg nog laughing so hard that line resonates so well it even tops clooney infamous hi freeze im batman line other classic moments is busey constantly getting upset for people reminding him that he got his excia partner killedwhich he did by accidentally shooting him in the chest all made possible by a super slowmotion flashback sequence that makes watching paint dry seem exciting there an ashtray to the nads punches to the face and a that was not my fault and you know it well the footage shows him missing the bad guy and hitting his buddy so other scream outloud moments has to be his ex girlfriend dropping a grenade to the ground to enable his escapea plan that defies all logic physics and absurdity and lastly when mcbain jumps out of the thunderblast during intense guerrilla warfare and starts to run and hurdles a small object i almost wet myself some of busey best work by far rent or buy it today butthorn my vote is a perfect 10 on the poo meter that is', shape=(), dtype=string)\n",
      "Label tf.Tensor(1, shape=(), dtype=int32)\n",
      "Vectorized review tf.Tensor(\n",
      "[  91   57  845   12    1  292 1395    4    1    9   25    1    1   11\n",
      "   20    7   81    4  328    1   19   28   10  482 1309    2   88  638\n",
      "  219    7    2   90    1  638  219    9   98   20  343   83    1    3\n",
      "   93   16    4    1    1    1    1    2    1  356    9   98   20  120\n",
      "    1  234 1563    1   10    1   58   48    5   56    1    1 1062   36\n",
      "  254   12  356    1   36   75    8   55    1    1    1    1    1  141\n",
      " 1427  356   82  345  373    7    1 1247  369    1   17   77    1   89\n",
      "   12   23  178   25    1 1978    1   23   70   31    1 1204   89    9\n",
      "    2    1   30   92  570   31    4 1629    1    1  668   12  155  144\n",
      "    1    1  291 1072   38   32    1    6    2    1    1    6    2  388\n",
      "    3    4   12   14   13   56    1    3   24  119    8   75    2  870\n",
      "  273   89  977    2   83  220    3    1   25    1   36   82 1913    1\n",
      "  373   44    6   27   25    1 1000    1    4    1    6    2 1649    6\n",
      "    1   25    1 1241   12    1   30 1937    1    3    1    3    1   51\n",
      "    1    1   46    5    2    1  299 1586    1    1    3  476    6  517\n",
      "    3    1    4  384    1   10  206    1  522   48    5    1  116  153\n",
      "   31  225  823   40  769    8  487    1   56    1    7    4  385  293\n",
      "   21    2    1    1   12    7    0    0    0    0    0    0], shape=(250,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print_one = True\n",
    "if print_one:\n",
    "    text_batch, label_batch = next(iter(train_ds))\n",
    "    first_review, first_label = text_batch[10], label_batch[10]\n",
    "    print(\"Review\", custom_standardization(first_review))\n",
    "    print(\"Label\", first_label)\n",
    "    print(\"Vectorized review\", vectorize_layer(first_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for training the word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6525/20000 [03:31<07:17, 30.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/brenda/ImdbLSTM/sentimento_imdb.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mseq\u001b[39m}\u001b[39;00m\u001b[39m => \u001b[39m\u001b[39m{\u001b[39;00m[inverse_vocab[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m seq]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Create\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m targets, contexts, labels \u001b[39m=\u001b[39m generate_training_data(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     sequences\u001b[39m=\u001b[39;49msequences,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     window_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     neg_samples\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     vocab_size\u001b[39m=\u001b[39;49mdictionary_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m targets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(targets)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m contexts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(contexts)[:,:,\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/ImdbLSTM/aux_we.py:37\u001b[0m, in \u001b[0;36mgenerate_training_data\u001b[0;34m(sequences, window_size, neg_samples, vocab_size, seed)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m target_word, context_word \u001b[39min\u001b[39;00m positive_skip_grams:\n\u001b[1;32m     35\u001b[0m   context_class \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(\n\u001b[1;32m     36\u001b[0m       tf\u001b[39m.\u001b[39mconstant([context_word], dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   negative_sampling_candidates, _, _ \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mlog_uniform_candidate_sampler(\n\u001b[1;32m     38\u001b[0m       true_classes\u001b[39m=\u001b[39;49mcontext_class,\n\u001b[1;32m     39\u001b[0m       num_true\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m       num_sampled\u001b[39m=\u001b[39;49mneg_samples,\n\u001b[1;32m     41\u001b[0m       unique\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     42\u001b[0m       range_max\u001b[39m=\u001b[39;49mvocab_size,\n\u001b[1;32m     43\u001b[0m       seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m     44\u001b[0m       name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnegative_sampling\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     46\u001b[0m   \u001b[39m# Build context and label vectors (for one target word)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m   negative_sampling_candidates \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(\n\u001b[1;32m     48\u001b[0m       negative_sampling_candidates, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/candidate_sampling_ops.py:148\u001b[0m, in \u001b[0;36mlog_uniform_candidate_sampler\u001b[0;34m(true_classes, num_true, num_sampled, unique, range_max, seed, name)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m\"\"\"Samples a set of classes using a log-uniform (Zipfian) base distribution.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[39mThis operation randomly samples a tensor of sampled classes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m    of each of `sampled_candidates`.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m seed1, seed2 \u001b[39m=\u001b[39m random_seed\u001b[39m.\u001b[39mget_seed(seed)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m gen_candidate_sampling_ops\u001b[39m.\u001b[39;49mlog_uniform_candidate_sampler(\n\u001b[1;32m    149\u001b[0m     true_classes, num_true, num_sampled, unique, range_max, seed\u001b[39m=\u001b[39;49mseed1,\n\u001b[1;32m    150\u001b[0m     seed2\u001b[39m=\u001b[39;49mseed2, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_candidate_sampling_ops.py:629\u001b[0m, in \u001b[0;36mlog_uniform_candidate_sampler\u001b[0;34m(true_classes, num_true, num_sampled, unique, range_max, seed, seed2, name)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m    628\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m    630\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mLogUniformCandidateSampler\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, true_classes, \u001b[39m\"\u001b[39;49m\u001b[39mnum_true\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    631\u001b[0m       num_true, \u001b[39m\"\u001b[39;49m\u001b[39mnum_sampled\u001b[39;49m\u001b[39m\"\u001b[39;49m, num_sampled, \u001b[39m\"\u001b[39;49m\u001b[39munique\u001b[39;49m\u001b[39m\"\u001b[39;49m, unique, \u001b[39m\"\u001b[39;49m\u001b[39mrange_max\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    632\u001b[0m       range_max, \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m, seed, \u001b[39m\"\u001b[39;49m\u001b[39mseed2\u001b[39;49m\u001b[39m\"\u001b[39;49m, seed2)\n\u001b[1;32m    633\u001b[0m     _result \u001b[39m=\u001b[39m _LogUniformCandidateSamplerOutput\u001b[39m.\u001b[39m_make(_result)\n\u001b[1;32m    634\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_stuff = False\n",
    "\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "if print_stuff:\n",
    "    print('Part of vocab:',inverse_vocab[:200])\n",
    "\n",
    "# Vectorize the data in text_ds\n",
    "text_vector_ds = text_ds.prefetch(AUTOTUNE).map(vectorize_layer)\n",
    "lst = list(text_vector_ds.as_numpy_iterator())\n",
    "sequences = lst[0]\n",
    "for i in range(1,len(lst)):\n",
    "    arr = np.asarray(lst[i])\n",
    "    sequences = np.append(sequences, arr, 0)\n",
    "sequences.reshape(-1)\n",
    "print(sequences.shape)\n",
    "\n",
    "if print_stuff:\n",
    "    print(len(sequences)*batch_size)\n",
    "    for seq in sequences[2][:1]:\n",
    "        print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")\n",
    "\n",
    "# Create\n",
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=5,\n",
    "    neg_samples=10,\n",
    "    vocab_size=dictionary_size,\n",
    "    seed=seed)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)[:,:,0]\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 17:09:20.032093: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3188231448 exceeds 10% of free system memory.\n",
      "2022-10-12 17:09:22.395955: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3188231448 exceeds 10% of free system memory.\n",
      "2022-10-12 17:09:24.589316: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3188231448 exceeds 10% of free system memory.\n",
      "2022-10-12 17:09:25.383201: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3188231448 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 101), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 101), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3853/3853 [==============================] - 17s 4ms/step - loss: 4.3908 - accuracy: 0.0639\n",
      "Epoch 2/200\n",
      "3853/3853 [==============================] - 17s 4ms/step - loss: 4.3158 - accuracy: 0.0730\n",
      "Epoch 3/200\n",
      " 836/3853 [=====>........................] - ETA: 12s - loss: 4.2941 - accuracy: 0.0753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/brenda/ImdbLSTM/sentimento_imdb.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m w2v\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m             loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m w2v\u001b[39m.\u001b[39;49mfit(dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B150.162.14.45/home/brenda/ImdbLSTM/sentimento_imdb.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m        epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2683\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2679\u001b[0m   cache_key, cache_key_deletion_observer \u001b[39m=\u001b[39m function_context\u001b[39m.\u001b[39mmake_cache_key(\n\u001b[1;32m   2680\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflat_input_signature)\n\u001b[1;32m   2682\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2683\u001b[0m   \u001b[39mhash\u001b[39;49m(cache_key)\n\u001b[1;32m   2684\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   2685\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2686\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mArguments supplied to `defun`-generated functions must be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2687\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhashable.  Original error: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_cache.py:76\u001b[0m, in \u001b[0;36mFunctionCacheKey.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39;49m((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_context, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_signature))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/default_types.py:136\u001b[0m, in \u001b[0;36mOrderedCollection.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 136\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39;49m((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomponents))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/default_types.py:136\u001b[0m, in \u001b[0;36mOrderedCollection.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 136\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39;49m((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomponents))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/default_types.py:335\u001b[0m, in \u001b[0;36mReference.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 335\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39;49m((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49midentifier, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/type_spec.py:447\u001b[0m, in \u001b[0;36mTypeSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 447\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_cmp_key())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_spec.py:76\u001b[0m, in \u001b[0;36mDenseSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 76\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39;49m((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_dim=10\n",
    "neg_samples=20\n",
    "\n",
    "#Train WE\n",
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, dictionary_size=dictionary_size, embedding_dim=embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(dictionary_size,\n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(dictionary_size,\n",
    "                                       embedding_dim,\n",
    "                                       input_length=neg_samples+1)\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
    "    # context: (batch, context)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch, context, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    # dots: (batch, context)\n",
    "    return dots\n",
    "\n",
    "w2v = Word2Vec(dictionary_size, embedding_dim)\n",
    "\n",
    "w2v.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "            \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "w2v.fit(dataset,\n",
    "       epochs=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save weigts of trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w2v.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save vectors and words in .tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process vectors from tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('vectors.tsv', sep=\"\\t\")\n",
    "df2 = pd.read_csv('metadata.tsv', sep=\"\\t\")\n",
    "\n",
    "vecs = df.values\n",
    "wrds = df2.values\n",
    "\n",
    "num_tokens = dictionary_size\n",
    "\n",
    "#Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for i in range(1,len(vecs)+1):\n",
    "    embedding_matrix[i] = vecs[i]\n",
    "    if (i%100==0):\n",
    "        print(wrds[i], '=', inverse_vocab[i])\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")\n",
    "\n",
    "os.remove('metadata.tsv')\n",
    "os.remove('vectors.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 126ms/step - loss: 0.6935 - accuracy: 0.4995 - val_loss: 0.6930 - val_accuracy: 0.5020\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 3s 142ms/step - loss: 0.6930 - accuracy: 0.4995 - val_loss: 0.6928 - val_accuracy: 0.5020\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 0.6928 - accuracy: 0.4995 - val_loss: 0.6926 - val_accuracy: 0.5020\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.6926 - accuracy: 0.4995 - val_loss: 0.6925 - val_accuracy: 0.5020\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 0.6924 - accuracy: 0.4995 - val_loss: 0.6924 - val_accuracy: 0.5020\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.6923 - accuracy: 0.4995 - val_loss: 0.6923 - val_accuracy: 0.5020\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 2s 106ms/step - loss: 0.6922 - accuracy: 0.4995 - val_loss: 0.6922 - val_accuracy: 0.5020\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.6921 - accuracy: 0.4995 - val_loss: 0.6921 - val_accuracy: 0.5020\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.6920 - accuracy: 0.4995 - val_loss: 0.6921 - val_accuracy: 0.5020\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 2s 119ms/step - loss: 0.6919 - accuracy: 0.4995 - val_loss: 0.6920 - val_accuracy: 0.5020\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.6918 - accuracy: 0.4995 - val_loss: 0.6919 - val_accuracy: 0.5020\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.6917 - accuracy: 0.4995 - val_loss: 0.6918 - val_accuracy: 0.5020\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.6916 - accuracy: 0.4995 - val_loss: 0.6917 - val_accuracy: 0.5020\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.6915 - accuracy: 0.4995 - val_loss: 0.6916 - val_accuracy: 0.5020\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.6913 - accuracy: 0.4995 - val_loss: 0.6916 - val_accuracy: 0.5020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 69154), started 2 days, 14:04:49 ago. (Use '!kill 69154' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dbd7d0b4db9379fe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dbd7d0b4db9379fe\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  vectorize_layer,\n",
    "  embedding_layer,\n",
    "  LSTM(4),\n",
    "  Dense(2),\n",
    "  Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "os.rmdir(\"logs\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3caeb8b0f137d67a92c8e1167310073f0bfb2e774977601549773a9d0ef48812"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
